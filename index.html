<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="URL OF THE WEBSITE"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>Learned Off-aperture Encoding for Wide Field-of-view RGBD Imaging</title>
  <link rel="icon" type="image/x-icon" href="static/images/favicon.ico">
  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro"
  rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet"
  href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.5.1/jquery.min.js"></script>
  <script src="https://documentcloud.adobe.com/view-sdk/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <link href="https://fonts.cdnfonts.com/css/linux-biolinum" rel="stylesheet">
  <style>
    @import url('https://fonts.cdnfonts.com/css/linux-biolinum');
  </style>
</head>
<body>
  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">Learned Off-aperture Encoding for <br> Wide Field-of-view RGBD Imaging</h1>
              <div class="is-size-5 publication-authors">
                <!-- Paper authors -->
                <span class="author-block">
                  <a href="https://whywww.github.io/" target="_blank">Haoyu Wei</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://liux2018.github.io/" target="_blank">Xin Liu</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://lorenaliu.notion.site/" target="_blank">Yuhui Liu</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://fuqiangx.github.io/" target="_blank">Qiang Fu</a><sup>2</sup>,</span>
                <span class="author-block">
                  <a href="https://vccimaging.org/People/heidriw/" target="_blank">Wolfgang Heidrich</a><sup>1,2</sup>,</span>
                <span class="author-block">
                  <a href="https://www.eee.hku.hk/~elam/" target="_blank">Edmund Y. Lam</a><sup>1</sup>,</span>
                <span class="author-block">
                  <a href="https://www.eee.hku.hk/~evanpeng/" target="_blank">Yifan (Evan) Peng</a><sup>1</sup></span>
              </div>

              <div class="is-size-5 publication-authors">
                <span class="author-block"><sup>1</sup>The University of Hong Kong (HKU),<sup>2</sup>King Abdullah University of Science and Technology (KAUST)<br><b>IEEE, Transactions on Pattern Analysis and Machine Intelligence (TPAMI), 2025</b><br>(To be updated)</span>
              </div>

              <div class="column has-text-centered">
                <div class="publication-links">
                  <!-- Arxiv PDF link -->
                  <span class="link-block">
                    <a href="" target="_blank"
                    class="external-link button is-normal is-rounded button-color">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Paper</span>
                    </a>
                  </span>

                  <!-- Supplementary PDF link -->
                  <span class="link-block">
                    <a href="" target="_blank"
                    class="external-link button is-normal is-rounded button-color">
                    <span class="icon">
                      <i class="fas fa-file-pdf"></i>
                    </span>
                    <span>Supplementary</span>
                    </a>
                  </span>

                  <!-- Github link -->
                  <span class="link-block">
                    <a href="" target="_blank"
                    class="external-link button is-normal is-rounded button-color">
                    <span class="icon">
                      <i class="fab fa-github"></i>
                    </span>
                    <span>Code</span>
                    </a>
                  </span>

                  <!-- ArXiv abstract Link -->
                  <!-- <span class="link-block">
                    <a href="https://arxiv.org/abs/<ARXIV PAPER ID>" target="_blank"
                    class="external-link button is-normal is-rounded is-dark">
                    <span class="icon">
                      <i class="ai ai-arxiv"></i>
                    </span>
                    <span>arXiv</span>
                    </a>
                  </span> -->
            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- Teaser -->
<div class="hero-body">
  <div class="container">
    <div class="item">
      <img src="static/images/teaser.png" alt="MY ALT TEXT" class="teaser-image"/>
      <h2 class="subtitle has-text-centered">
        (Left) Depiction of three potential locations for integrating a DOE for encoding purposes in an imaging system. The on-aperture DOE has many degrees of freedom to affect each ray bundle, but all of them are applied globally to the whole image plane. On the other hand, a DOE near the sensor provides localized control of the PSF, but with much fewer degrees of freedom for each ray bundle. The off-aperture DOE strikes an optimal balance between these two extremes. (Center-left) Cross-sectional view of two custom-fabricated optical imaging systems. The DOEs and apertures are located at separate planes. (Center-right) Resolved wide-FoV results of App. 1 compared to encoded measurements; (Right) Color and depth results of App. 2.
      </h2>
    </div>
  </div>
</div> 

<!-- Teaser video-->
<section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video poster="" id="tree" controls loop height="100%">
        <source src="static/videos/Off-Aperture-Encoded-Imaging.mp4"
        type="video/mp4">
      </video>
      <!-- <h2 class="subtitle has-text-centered">
        Aliquam vitae elit ullamcorper tellus egestas pellentesque. Ut lacus tellus, maximus vel lectus at, placerat pretium mi. Maecenas dignissim tincidunt vestibulum. Sed consequat hendrerit nisl ut maximus. 
      </h2> -->
    </div>
  </div>
</section>
<!-- End teaser video -->

<!-- Paper abstract -->
<section class="section hero is-light">
  <div class="container is-max-desktop">
    <div class="columns is-centered has-text-centered">
      <div class="column is-full">
        <h2 class="title is-3">Abstract</h2>
        <div class="content has-text-justified">
          <p>
            End-to-end (E2E) designed imaging systems integrate coded optical designs with decoding algorithms to enhance imaging fidelity for diverse visual tasks. However, existing E2E designs encounter significant challenges in maintaining high image fidelity at wide fields of view, due to high computational complexity, as well as difficulties in modeling off-axis wave propagation while accounting for off-axis aberrations. In particular, the common approach of placing the encoding element into the aperture or pupil plane results in only a global control of the wavefront. To overcome these limitations, this work explores an additional design choice by positioning a DOE <em>off-aperture</em>, enabling a spatial unmixing of the degrees of freedom and providing local control over the wavefront over the image plane.  Our approach further leverages hybrid refractive-diffractive optical systems by linking differentiable ray and wave optics modeling, thereby optimizing depth imaging quality and demonstrating system versatility. Experimental results reveal that the off-aperture DOE enhances the imaging quality by over 5dB in PSNR at a FoV of approximately 45° when paired with a simple thin lens, outperforming traditional on-aperture systems. Furthermore, we successfully recover color and depth information at nearly 28° FoV using off-aperture DOE configurations with compound optics. Physical prototypes for both applications validate the effectiveness and versatility of the proposed method.
          </p>
        </div>
      </div>
    </div>
  </div>
</section>
<!-- End paper abstract -->


<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title">Application 1: Wide-FoV Simple Lens Imaging</h2>
      <div class="item">
        <p>
          Our wide-FoV imaging setup includes a simple focusing lens with an approximate FoV of 45° and a rotational symmetric off-aperture DOE, effectively compensating for most aberrations. 
          State-of-the-art coded-aperture and/or deep optics imaging solutions mostly assume spatial-invariant PSF behavior and demonstrate in experiments a FoV up to 30°.
        </p>
        <img src="static/images/app1-psfs.png" class="sec-image"/>
        <div class="subtitle has-text-centered">
          (Top-left) The conceptual system setup of an off-the-shelf thin lens and an off-aperture DOE. (Bottom-left) The fitted PSNR plots for recovered images across various DOE locations shows that the optimal location is a trade-off point between the aperture and the sensor. The optimal DOE location for each dataset is approximately 0.24. (Right) Comparison of PSF amplitudes at several FoVs when the DOE is placed at different locations.
        </div>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <video poster="" id="tree" autoplay controls muted loop width="100%">
              <source src="static/videos/app1-scene1.mov" type="video/mp4">
            </video>
            <div class="subtitle has-text-centered">
              Indoor and outdoor experimental results for the application of wide-FoV simple lens imaging. The equivalent f-number is 12. ISO is set as 100 for all captures.
            </div>
          </div>
          <div class="item is-centered">
            <video poster="" id="tree" autoplay controls muted loop width="50%"  class="sec-image">
              <source src="static/videos/video.mov" type="video/mp4">
            </video>
            <div class="subtitle has-text-centered">
              A video clip of the wide-FoV simple lens imaging application. The reconstructions demonstrate good temporal consistancy.
            </div>
          </div>
        </div>
      </div>
</section>

<section class="section is-compact">
  <div class="container is-max-desktop content">
    <h2 class="title">Application 2: Wide-FoV Compound Lens RGBD Imaging</h2>
      <div class="item">
        <p>
          We introduce a compound optics prototype designed for wide-FoV depth and color imaging. The system combines an optimized Cooke triplet as the focusing lens module, achieving a practical balance between compactness and aberration correction.
        </p>
        <img src="static/images/app2-psfs.png" class="sec-image"/>
        <div class="subtitle has-text-centered">
          (Left) Optimized PSFs at depths from 0.8 m to 10 m and FoVs up to 28°, using the off-aperture large-FoV EDoF imaging system. Depth layers are sampled uniformly. (Top-right) The 3D model of the optimized system, where the dotted line denotes the location to place the near-aperture DOE. Figure visualization is not drawn to scale. (Bottom-right) Optimized DOE height maps for near (around 0.11) and off aperture (around 0.24) settings.
        </div>
        <div id="results-carousel" class="carousel results-carousel">
          <div class="item">
            <video poster="" id="tree" autoplay controls muted loop height="100%">
              <source src="static/videos/app2-scene1.mov" type="video/mp4">
            </video>
            <div class="subtitle has-text-centered">
              Indoor and outdoor experimental results for App. 2: wide-FoV AiF and depth imaging. For each scene, we present the captured and reconstructed halves of color images (top), along with their zoom-in patches (bottom-right) and estimated depth map (bottom-left). The equivalent f-number is 7, and the gain set 0 for all captures.
            </div>
          </div>
          <div class="item">
            <video poster="" id="tree" autoplay controls muted loop height="100%">
              <source src="static/videos/app2-scene2.mov" type="video/mp4">
            </video>
            <div class="subtitle has-text-centered">
              Indoor and outdoor experimental results for App. 2: wide-FoV AiF and depth imaging. For each scene, we present the captured and reconstructed halves of color images (top), along with their zoom-in patches (bottom-right) and estimated depth map (bottom-left). The equivalent f-number is 7, and the gain set 0 for all captures.
            </div>
          </div>
        </div>
      </div>
    </div>
</section>

<!-- Method -->
<section class="section is-compact">
  <div class="container is-max-desktop content">
    <h2 class="title">System Pipeline</h2>
      <div class="item">
        <img src="static/images/pipeline.png" alt="MY ALT TEXT" class="sec-image"/>
        <div class="subtitle has-text-centered">
          Imaging pipeline of our proposed system. We model the camera’s light propagation using a combination of ray tracing and wave propagation. The DOE placed in-between the lens module and the sensor facilitates information encoding. A multi-head decoding network based on the ResNet architecture is incorporated to support optimization for multiple visual tasks.
        </div>
        <img src="static/images/components.jpg" alt="MY ALT TEXT" class="sec-image" style="width: 80%;"/>
        <div class="subtitle has-text-centered">
          (Left) App. 1 prototyping includes an aperture, a thin lens, and a DOE; (Center) The experimental setup. (Right) App. 2 prototype includes an aperture, three refractive lenses, and a DOE.
        </div>
      </div>
    </div>
</section>


<!-- Image carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <div id="results-carousel" class="carousel results-carousel">
      <div class="item">
        <img src="static/images/results.png" alt="MY ALT TEXT" class="abs-image"/>
        <h2 class="subtitle has-text-centered">
          (a) Visual results of the amplitude (first row) and phase (second row) of the complex PSF, and the amplitude for the angular spectrum (third row) of the input field at 3 degrees. The amplitude of the PSF and the angular spectrum is normalized by respective maxima. In the third row, the red dots denote the center of the angular spectrum. (b) SNR and runtime w.r.t. incident angles. (c) Sampling number w.r.t. incident angles. 
        </h2>
      </div>
      <div class="item">
        <img src="static/images/uniform-diffuser.png" alt="MY ALT TEXT" class="abs-image"/>
        <h2 class="subtitle has-text-centered">
          Complex diffractive fields modulated by random diffusers with uniform distributions within each pixel. Here the phase modulation is wrapped to [0, 2π] for visualization.
       </h2>
     </div>
  </div>
</div>
</div>
</section> -->
<!-- End image carousel -->


<!-- Youtube video -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Video Presentation</h2>
      <div class="columns is-centered has-text-centered">
        <div class="column is-four-fifths">
          
          <div class="publication-video">
            <iframe src="https://www.youtube.com/embed/JkaxUblCGz0" frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
          </div>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End youtube video -->


<!-- Video carousel -->
<!-- <section class="hero is-small">
  <div class="hero-body">
    <div class="container">
      <h2 class="title is-3">Another Carousel</h2>
      <div id="results-carousel" class="carousel results-carousel">
        <div class="item item-video1">
          <video poster="" id="video1" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel1.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video2">
          <video poster="" id="video2" autoplay controls muted loop height="100%"> -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel2.mp4"
            type="video/mp4">
          </video>
        </div>
        <div class="item item-video3">
          <video poster="" id="video3" autoplay controls muted loop height="100%">\ -->
            <!-- Your video file here -->
            <!-- <source src="static/videos/carousel3.mp4"
            type="video/mp4">
          </video>
        </div>
      </div>
    </div>
  </div>
</section> -->
<!-- End video carousel -->


<!-- Paper poster -->
<!-- <section class="hero is-small is-light">
  <div class="hero-body">
    <div class="container">
      <h2 class="title">Poster</h2>

      <iframe  src="static/pdfs/sample.pdf" width="100%" height="550">
          </iframe>
        
      </div>
    </div>
  </section> -->
<!--End paper poster -->


<!--BibTex citation -->
<section class="section is-compact" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>
      @article{wei2025learned,
        title   = {Learned Off-aperture Encoding for Wide Field-of-view RGBD Imaging},
        author  = {Wei, Haoyu and Liu, Xin and Liu, Yuhui and Fu, Qiang and Heidrich, Wolfgang and Lam, Edmund Y. and Peng, Yifan},
        journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
        year    = {2025}
      }
    </code></pre>
  </div>
</section>
<!--End BibTex citation -->
<!-- month   = jul, -->
<!-- volume  = {10}, number = {7}, pages = {959--962}, -->
<!-- publisher = {Optica Publishing Group}, -->
<!-- doi     = {10.1364/OPTICA.490223} -->


<!-- Related projects -->
<section class="section">
  <div class="container is-max-desktop content">
    <h2 class="title">Related Projects</h2>
    You may also be interested in related projects in deep optics:
    <ul>
      <li>Liu et al. Coded stereo RGBD imaging, CVPR (Oral) 2025 (<a href="https://liangxunou.github.io/25liulearned/">link</a>)</li>
      <li>Shi et al. Array-DOE for Hyperspectral Imaging, ACM ToG (Siggraph Asia) 2024 (<a href="https://whywww.github.io/ArrayHSI/">link</a>)</li>
      <li>Wei et al. Efficient Off-Axis Diffractive Modeling (LS-ASM), Optica 2023 (<a href="https://whywww.github.io/LSASM_page/">link</a>)</li>
      <li>Peng et al. Large FoV Imaging with Thin Plate Optics, ACM ToG (Siggraph) 2019 (<a href="https://vccimaging.org/Publications/Peng&Sun2019LearnLargeFOV/">link</a>)</li>
    </ul>
  </div>
</section>
<!-- End related projects -->


<footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">
          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a>.
            This content is released under the Creative Commons Attribution-NonCommercial 4.0 International license (CC BY-NC.) 
          </p>
        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->
<!-- Default Statcounter code for My Personal Website https://whywww.github.io/ -->
<script type="text/javascript">
  var sc_project=12906744; 
  var sc_invisible=1; 
  var sc_security="5b484c07"; 
  </script>
  <script type="text/javascript"
  src="https://www.statcounter.com/counter/counter.js" async></script>
  <noscript><div class="statcounter"><a title="Web Analytics"
  href="https://statcounter.com/" target="_blank"><img class="statcounter"
  src="https://c.statcounter.com/12906744/0/5b484c07/1/" alt="Web Analytics"
  referrerPolicy="no-referrer-when-downgrade"></a></div></noscript>
<!-- End of Statcounter Code -->

  </body>
  </html>
